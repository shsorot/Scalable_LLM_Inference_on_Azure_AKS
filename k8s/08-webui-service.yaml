# Public LoadBalancer service for Open-WebUI
# Exposes the chat interface to demo attendees
---
apiVersion: v1
kind: Service
metadata:
  name: open-webui
  namespace: ollama
  labels:
    app: open-webui
    app.kubernetes.io/name: open-webui
    app.kubernetes.io/component: web-frontend
  annotations:
    # Increase idle timeout to 30 minutes for long-running LLM responses
    service.beta.kubernetes.io/azure-load-balancer-tcp-idle-timeout: "30"
    # Disable connection draining to prevent streaming interruption
    service.beta.kubernetes.io/azure-load-balancer-disable-tcp-reset: "true"
    # Enable HTTP/1.1 keepalive for streaming
    service.beta.kubernetes.io/azure-load-balancer-enable-high-availability-ports: "false"
spec:
  type: LoadBalancer
  selector:
    app: open-webui
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 8080
  sessionAffinity: ClientIP  # Maintain user sessions
